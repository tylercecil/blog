---
title: Words that Ever Play Well
subtitle: Part II on Negative Polarity Items
abstract: >
  In Part II we dive into the work of Anastasia Giannakidou, and come up with a
  new, more general, more powerful, and more correct licensing condition:
  the *variation approach*.

header-includes: >
  <style>
    blockquote {
      margin-bottom: 2.5rem;
      margin-left: 0;
      margin-right: 0;
    }

    blockquote > ol, blockquote > p {
      margin: 0 .2rem;
      font-size: 110%;
      background: #F1F1F1;
      border: 1px solid #E1E1E1;
      border-radius: 4px;
      padding: 1rem 1.5rem;
    }

    /* I'll use ~~ ~~ to mark bad sentences */
    del {
      color: red;
      text-decoration: none;
    }

    dl {
      background: #F1F1F1;
      border: 1px solid #E1E1E1;
      border-radius: 4px;
      padding: 1rem 1.5rem;
    }

    dt::before {
      font-weight: bold;
    }

    dt {
      font-weight: bold;
    }
  </style>
---

Review
======
[In Part I](./2020-01-19-NPI.html) we introduced *Negative Polarity Items*, a
special class of words that just don't seem to *ever* play right. We tried to
tackle the question **"in what contexts can we use NPIs?"**.

Ultimately we came up with (what I would call) a pretty compelling answer;
*downward entailment* is when something you know about $X$ tells you
something about a subset of $X$.

> (@dd) No dog can fly. $\vdash$ No talking dog can fly.
> (@du) A talking dog can fly. $\vdash$ A dog can fly.

Because "talking dogs" $\subseteq$ "dogs", we call (@dd) a *downward
entailment* and (@du) an *upward entailment*. And the magic is that **DEs
*licence* our troublesome NPIs**!

> No dog can *ever* fly.\
> ~~#A dog can *ever* fly.~~

In the end, however, we were left with a problematic sentence:

> Exactly 10 people have *ever* been to my house.

This sentence is **neither upward nor downward entailing.** In this post, we're
going to do something about that!

If you're reading this, I'm assuming Part I already got your attention. So, if
you'll permit me, I'm going to get a *little more technical* here. Time to
put on our big-kid-amateur-semanticist pants!

The Big Picture
===============
Before we get started, let's take a deep breath and ask ourselves, **"why does
this matter?"** It's fun, sure, but does it have a real impact on our ideas
of language?

Well-Formedness
---------------
To answer your question:

> (@col) Colorless green ideas sleep furiously.

Noam Chompsky said that, and I think he knows a thing or two! It was to
demonstrate (among other things) **there exists well-formed sentences that are
meaningless**. So what do I mean by well-formed?

> (@bcol) ~~#Furiously sleep ideas green colorless.~~

You're brain was able to "read" (@col). Were I to ask you "what sleeps?" you
could respond "colorless green ideas... whatever that means." Example (@bcol),
however, hardly deserves the title "sentence". It is not *grammatically
well-formed*. Let's look at some other examples:

Table: "Meaningful" here really means *semantically* (as opposed to
  grammatically) well-formed.

Sentence                             Grammatic  Meaningful
-----------------------------------  ---------  -----------------------------
The talking dog can bark.            Yes        ~~No~~[^talkdog]
The talking dog bark can.            ~~No~~     ~~No~~[^almost]
The capital of Tyler is Vientiane.   Yes        ~~No~~[^capital]
The capital of Loas is Vientiane.    Yes        Yes
Blargs can run.                       Yes(ish)   ~~No~~[^blargs]
Blarg run home.                       ~~No~~     ~~No~~[^blarg]

[^talkdog]: "The talking dog can bark" is meaningless in a subtle kind of way.
  The problem is, it *presupposes* that there is a talking dog.  Because there
  is no such thing, the "subject" is an empty set.  "Colorless green things are
  bad" is more obviously wrong, but for the same reason --- there is no such
  thing. Interestingly, we are able to say what they *would* mean if there
  *were* such things.

[^almost]: One could argue "the dog bark can" is meaningful --- an English
  speaker could "get the gist", even though it's not a sentence. This is
  another topic for another day.

[^capital]: This kind of error is known as a *category faliure*. It's a kind of
  lexical anomaly that bind certain categories together. Here, the lexical
  category of people may not possess capitals.

[^blargs]: Although "blargs" isn't a word, it fits the phonetic rules of
  English.  Any speaker would be able to identify it as a plural noun.

[^blarg]: Again, the phonetics of English tell us that "blarg" must be a
  singular noun. This, then, is a morphology problem --- "run" cannot be used
  with a singular subject.

NPI Errors
----------
What about ~~"#I found *anyone*"~~? Is that a failure of meaning, like (@col),
or of grammar, like (@bcol)? Qualitatively, it feels closer to a grammar
problem than a semantic problem.[^psych] It has that "it hurts my ears" quality
to it.

[^psych]: I am almost entirely ignorant of psycho-linguistics, but there is
  fascinating data to support this. Biophasic N400 patterns reflect attempts to
  process a sentence syntactically. P600 patterns reflect attempts to process
  information semantically. NPI errors illicit *both* patterns, suggesting
  **NPI errors are taking place at both the semantic and syntactic level.**

And that is my (somewhat abstract) point --- we have been talking about NPI
errors as *semantic* in nature, having to do with what a sentence *means*,
rather than the structure of the sentence itself. Well-formedness, however, is
thought of as being essentially *syntactic*. **NPI errors bring into question
whether semantics play a roll in well-formedness.**

Situations Not Covered by DE
============================
OK, back to the task at hand! We've already found one example where DE seemed
to fail us.  We labeled it as *non-monotonic*, meaning neither UE nor DE. There
is a quick band-aid that could seem to save us --- non-UE. It is clear that
Non-UE $\subseteq$ DE.

"Exactly 10 people have ever been to my house" is, in fact, not upward
entailing. Unfortunately however, we can find more situations missed by non-UE.
We could say **non-UE underpredicts NPIs**. Let's look at some new
problem-sentences.

Questions
---------
> Have you *ever* seen *anyone*?

Questions don't have entailments like statements do. "Is this question UE or
DE" just doesn't make sense. Even Ladusaw, who first identified the
relationship between DE and NPIs, thought that this was a serious empirical
problem --- especially because NPIs in questions are extremely common across
all languages.

Imperatives
-----------
> Pick *any* painting.

Subtly, this isn't DE --- no one asked you to "pick *any blue
painting*". You *may*, but that would be a different sentence.

> Pick any painting. $\vdash$ You may pick any blue painting.\
> Pick any painting. $\not\vdash$ Pick any blue painting.

Others
------
In Giannakidou (2011) Section 3.2.3[^Giannakidou], a number of other examples
are laid out, including *habituals*, *deontic* sentences, and (probably most
interesting) *disjunction*. Most are non-obvious why they don't fall under DE,
and some don't have English equivalents. This post is already more technical
than I wanted, so let's just leave things easy for today.

A Solution
==========
Alright kids, buckle up! We started things off by talking about why this
matters --- the interface between semantics and grammar. Then we examined some
sentences which are not downward entailing, but which allow NPIs. Here's what I
want to do now:

1. Define a funky little term
2. Show that this term is a *superset* of DE
3. Show that it explains our problems

And the word of the day is **veridicality!**

(Non)veridacity
---------------
*Veridicality* is related to the truth or existence of something. Before we
define this, let's go strait to some examples:

------------------------------------    -----------------------------------------
**"I *found* the meaning of life."**    We could call "found" **veridical**,
                                        because it implies that there is a
                                        meaning of life.

**"I am *looking* for the meaning of    "Looking" does not imply there exists
life."**                                a meaning of life. We call it
                                        **non**veridical.

**"There is no meaning of life."**      This states the non-existence of the
                                        meaning of life. We could call it
                                        **anti**verdical. Note that
                                        antiveridical $\subseteq$ nonveridical.
-------------------------------------------------------------------------------

"Found", "looking", and "there is no" can all be called *operators*. They
operate on the existence of $p$, the meaning of life. If I *find* some $p$,
then I know that $p$ exists. I could write that as $O_\text{find}p \to
p$.[^exists]

[^exists]: If you're reading carefully, you'll note I'm conflating $p$ exists,
  and $p$ is true. This conflation is somewhat normal in semantics. You'll have
  to trust me that it doesn't break anything._

For practice, let's see what these sentences say (or don't say) about $p$:

---------------------------------  ---------------    ------------------
I found meaning of life.           $Op \to p$              **veridical**
I am looking for meaning of life.  $Op \not \to p$      **nonveridical**
There isn't meaning of life.       $Op \to \neg p$     **antiveridical**
-------------------------------------------------------------------------------

If we're going to use *veridicality* to solve our NPI woes, we're going to need
an accurate definition.

Veridical:
  : An operator $O$ is *veridical* if $Op \to p$.

If we test the NPI *any*, we can get an intuition about how this will work:

---------------------------------------    --------------------
~~#I found *any* meaning of life.~~               **veridical**
I am looking for *any* meaning of life.        **nonveridical**
There isn't *any* meaning of life.            **antiveridical**
---------------------------------------------------------------

The claim is that **nonveridacity licences NPIs**.

DE $\subseteq$ Nonveridacity
-----------------------------
The next step is to show that nonveridacity is a widening of DE, and not some
totally new unrelated concept. To do this, let's look at operators that take
*two* arguments --- things like "and" ($p \wedge q$), "or" ($p \vee q$),
"if/then" ($p \to q$), "with", "without", etc. We call these *connectives*.

Veridical Connective
  : A connective $C$ is said to be *veridical* with respect to $p$ if $pCq \to
  p$. That is, if one knows $pCq$, then one can infer $p$. For example $p
  \wedge q \to p$.

That's a very specific definition! What, then, does a DE connective look like?

Downward Connective
  : Let $C$ be a downward entailing connective with respect to $p$. Knowing $r
  \to p$ (whenever $r$ is true, $p$ is true) is enough to know $pCq \to rCq$.\
  **Example:**\
  "I will kill you" $\to$ "you will die".\
  "If you sleep with anyone, I will kill you" $\to$ "If you sleep with anyone,
  you will die".\
  "If $p$ then $q$" is DE with respect to $q$.

This is really the same definition we used in [Part
I](./2020-01-19-NPI.html#downward-entailment).  Showing that DE $\subseteq$
Nonveridacity is now very strait-forward. We can prove that **no connector $C$
can be both DE and veridical.**

1. Let $C$ be veridical and DE.
2. Assume $pCq$.
3. Note that $p \wedge \neg p \to p$.
4. Because $C$ is DE, we know $(p\wedge \neg p)Cq$.
5. Because $C$ is veridical, we know $(p\wedge\neg p)$.

This is obviously a contradiction, therefore $C$ was impossible![^lem] That
means that **any connector that is DE must be nonveridical.**

[^lem]: If you know much about my beliefs, you should know I'm cringing right
  now. There is so much to say about this proof, but this post is already way
  too long.

Nonveridacity: The NPI Context
------------------------------


There's Always More To It
==========================

Even "Stricter" NPIs &#8253;
---------------------------
*Antiveridacity*

A section on how this is an ever-moving target. Should talk about
cross-linguistics here.

*Over / Under generation should maybe be touched on?*

Notes to Me
===========
With the introduction of cross-linguistic analysis, at is clear that NPIs
don't all work the same way.

"Zwarts 1995 further presents a proof that DE functions are a subset of the
nonveridical, hence nonveridicality is not in competition bur rather a
conservative extension of DE, that affords a broader empirical coverage and
strengthens the semantic theory of NPIs in just the right way. "

Sub-speciation of PI's. String/nonstrict NPIs, PPIs, FCI, Minimizers

Linebarger, negation, Page 19. Interesting note. I could use this to talk about
pragmatic levels of rules, and say "I am told this doesn't work. In any case
it's not what I'm writing about today."

I also was noticing that there is a readability trade-off for cross-linguistic
examples. *I* tend to gloss over them and they make me get tired reading. But
a single block of them at the end would **reall** not be all that interesting.
So... What does that leave me with? I have some sources I could use for Hungarian,
German, Dutch, Romance languages, and Japanese, which coveres most languages
my readers have.

[^Giannakidou]: [Giannakidou, Anastasia.
  (2011)](https://www.researchgate.net/publication/255578263_Negative_and_positive_polarity_items_Variation_licensing_and_compositionality).
  Negative and positive polarity items: Variation, licensing, and
  compositionality. Semantics: An International Handbook of Natural
  Language Meaning.

